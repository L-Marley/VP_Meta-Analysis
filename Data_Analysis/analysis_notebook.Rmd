---
title: "Visual Perspective - Meta-Analysis"
author: Liam Marley
output: html_notebook:
  theme: flatly
  toc: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff=60), tidy = TRUE)
```

# Packages Used
```{r packages, warning=FALSE}
library(tidyverse)
library(metafor)
```

# Data Import and Tidying

## Load in the data
```{r data_loading}
qual_export <- read_csv("qual_export_30-07-18.csv")
```

## Data Tidying

Following chunk drops: the unecessary qualtrics variables and rows, correlational studies, and any research conducted at the memory level.

Correlational studies are dropped to be analysed separately, and studies done at the memory level have nearly always used single level statistics treating memories as participants. Which ignores the clustering and dependency in the data leading to spurious results. As such, they've been excluded as a form of quality control.

```{r}
qual_tidy <- 
  qual_export %>%
  select(-c(`Start Date`:`User Language`)) %>%
  filter(Analysis_Level == "Participants") %>%
  filter(Design_1 == "Experimental")
```
### Vividness Data

Only selects the variables to calculate effect sizes from and those that are necessary to identify the research source and potential moderators (emotional cues, clinical samples, and perspective nature).

Then renames these to variables more suited for conducting the analysis

Finally, it drops studies with any na values within these variables. Note, this will only drop studies that have no vividness scores not those with missing data, because missing data has been coded as -99 within qualtrics. 

```{r vividness_data}
vivid_dat <- 
  qual_tidy %>%
  select(Authors:Pub_Year, Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Vividness`, `Vividness - First_Mean`:`Vividness - Between_Test`, -c(`Vividness - First_Corr`, `Vividness - Third_Corr`, `Vividness - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Vividness`, first_mean = `Vividness - First_Mean`, third_mean = `Vividness - Third_Mean`, first_sd = `Vividness - First_SD`, third_sd = `Vividness - Third_SD`, first_n = `Vividness - First_N`, third_n = `Vividness - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 13 studies for vividness. Two of which are not independent samples.

Recodes any missing Ns or SDs as NA from the -99 now that the drop_na argument has been used. 
```{r vivid_nas}
# recode missing SDs as NAs
vivid_dat$first_sd <- na_if(vivid_dat$first_sd, -99.00)
vivid_dat$third_sd<- na_if(vivid_dat$third_sd, -99.00)

# recode missing Ns as NAs
vivid_dat$first_n <- na_if(vivid_dat$first_n, -99)
vivid_dat$third_n <- na_if(vivid_dat$third_n, -99)
```

## Orthagonal Contrasts

### Perspective Nature
```{r}
spon_vs_force <- c(-2, 1, 1)
deli_vs_shift <- c(0, -1, 1)
```

### Emotional
```{r emo_contrasts}
none_vs_emo <- c(-2, 1, 1)
pos_vs_neg <- c(0, -1, 1)
```

#### Effect sizes

Calculate the effect sizes for the vividness data
```{r vivid_effsiz}
vivid_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = vivid_dat)
```

For publication 28 it's possible to calculate Cohen's d despite the missings SDs using the t-value and group sizes.

To do so need to extract the t-value from the string intended for the p-curve analysis. 
```{r vivid_tval}
# define the pattern to match to
tval_pat <- " \\d\\.\\d\\d"

# extract the t-values into a new column
vivid_dat$tval <- str_extract(vivid_dat$Vividness...Between_Test, tval_pat)

# treat these as numeric values
vivid_dat$tval <- as.numeric(vivid_dat$tval)
```

Unfortunately I didn't use the t-value signs when coding due to the different approaches possible across published literature. In hindsight should have done so choosing our direction beforehand and converting any that broke this. 

Publication 28 states:
"In addition,the subjects rated field memories higher than observer memories in their richness of detail [means 5.0 vs. 3.9; t(50) = 3.27]" (McIsaac & Eich, 2002, pp. 147) 

This positive t-value matches the approach taken in the effect size calculations so doesn't need converting and the following chunk can be used

```{r}
# initialise an empty cohen's d variable
vivid_dat$dval[c(1:13)] <- NA

# use replace missing function from metafor to calculate cohen's d (all will be calculated for now although only 28 is of interest)
vivid_dat$dval <- replmiss(vivid_dat$dval, with(vivid_dat, tval * sqrt(1/first_n + 1/third_n)))
``` 

Now we can covert Cohen's d to Hedge's g to impute into the yi variable, crucially only the missing value it's possible to impute (28) will be replaced. Followed by imputing the sampling variance for the estimate (vi)

```{r vivid_28impute}
vivid_dat$yi <- replmiss(vivid_dat$yi, with(vivid_dat, (1 - 3/(4 * (first_n + third_n - 2) - 1)) * dval))
vivid_dat$vi <- replmiss(vivid_dat$vi, with(vivid_dat, 1/first_n + 1/third_n + yi^2/(2*(first_n + third_n))))
```

An estimate of the effect size could be done in a similar way for publication 1. IF we assume group sizes. The information for this study was sourced from study 3 in the paper. (Note to self, check where study id 1 has gone for this paper)

Amendment: Returning to the paper revealed that this is a within-subjects design. Using participants who'd reported at least one field and one observer memory. As such, this approach is not appropriate. 

#### Moderators

Following chunk specifies the moderators as being factors rather than relying on functions to coerce them from character to factor variables.
```{r vivid_factors}
vivid_dat$clinical_mod <- as.factor(vivid_dat$clinical_mod)
vivid_dat$emo_mod <- as.factor(vivid_dat$emo_mod)
vivid_dat$persp_mod <- as.factor(vivid_dat$persp_mod)
```

Check what the factor levels are
```{r}
levels(vivid_dat$clinical_mod)
levels(vivid_dat$emo_mod)
levels(vivid_dat$persp_mod)
```

Relevel the perspective moderator so that spontaneous perspective taking is the first level
```{r}
vivid_dat$persp_mod <- relevel(vivid_dat$persp_mod, ref = "Spontaneous (naturalistic)")
```

#### Retrospective t-value signs

After the realisation above decided to change the necessary t-value signs here within vividness. 
Inspecting the data set shows publications: 50, 136, and 63 (spontaneous) should be negatives.
```{r}
# Demonstrate current t-values etc
vivid_dat$Vividness...Between_Test[3]
vivid_dat$Vividness...Between_Test[8]
vivid_dat$Vividness...Between_Test[11]
# Replace with the correct negative t-values
vivid_dat$Vividness...Between_Test[3] <- "t(77.68) = -0.75, p = .458"
vivid_dat$Vividness...Between_Test[8] <- "t(41.62) = -2.28, p = .028"
vivid_dat$Vividness...Between_Test[11] <- "t(121.04) = -0.94, p = .349"
```

### Emotional Intensity Data

Follows exactky the same pattern and reasoning as the vividness data 

```{r intense_data}
intense_dat <- 
  qual_tidy %>%
  select(Authors:Pub_Year, Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Emotional Intensity`, `Emotional Intensity - First_Mean`:`Emotional Intensity - Between_Test`, -c(`Emotional Intensity - First_Corr`, `Emotional Intensity - Third_Corr`, `Emotional Intensity - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Emotional Intensity`, first_mean = `Emotional Intensity - First_Mean`, third_mean = `Emotional Intensity - Third_Mean`, first_sd = `Emotional Intensity - First_SD`, third_sd = `Emotional Intensity - Third_SD`, first_n = `Emotional Intensity - First_N`, third_n = `Emotional Intensity - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 11 studies for Emotional Intensity. All of which are independent samples.

```{r intense_nas}
# recode missing SDs as NAs
intense_dat$first_sd <- na_if(intense_dat$first_sd, -99.00)
intense_dat$third_sd<- na_if(intense_dat$third_sd, -99.00)

# recode missing Ns as NAs
intense_dat$first_n <- na_if(intense_dat$first_n, -99)
intense_dat$third_n <- na_if(intense_dat$third_n, -99)
```

#### Effect sizes

Calculate the effect sizes for the Emotional Intensity data
```{r intense_effsiz}
intense_dat$third_mean <- as.numeric(intense_dat$third_mean)
                                     
intense_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = intense_dat)
```

The same approach for imputing study 28's effect sizes without the SDs will be followed as the vividness dv. This time simply done within one chunk:
```{r intense_impute}
# extract the t-values into a new column
intense_dat$tval <- str_extract(intense_dat$Emotional.Intensity...Between_Test, tval_pat)

# treat these as numeric values
intense_dat$tval <- as.numeric(intense_dat$tval)

# initialise an empty cohen's d variable
intense_dat$dval[c(1:11)] <- NA

# use replace missing function from metafor to calculate cohen's d 
intense_dat$dval <- replmiss(intense_dat$dval, with(intense_dat, tval * sqrt(1/first_n + 1/third_n)))

# convert Cohen's d to Hedge's g
intense_dat$yi <- replmiss(intense_dat$yi, with(intense_dat, (1 - 3/(4 * (first_n + third_n - 2) - 1)) * dval))

# calculate sample variance
intense_dat$vi <- replmiss(intense_dat$vi, with(intense_dat, 1/first_n + 1/third_n + yi^2/(2*(first_n + third_n))))
```

#### Moderators

Coerce moderators into factor variables
```{r intense_factors}
intense_dat$clinical_mod <- as.factor(intense_dat$clinical_mod)
intense_dat$emo_mod <- as.factor(intense_dat$emo_mod)
intense_dat$persp_mod <- as.factor(intense_dat$persp_mod)
```

Check what the factor levels are
```{r intense_levels}
levels(intense_dat$clinical_mod)
levels(intense_dat$emo_mod)
levels(intense_dat$persp_mod)
```

Control groups should be equivalent to no clinical sample studies. As such, these two levels will be collapsed
```{r}
intense_dat$clinical_mod <- fct_recode(intense_dat$clinical_mod, No = "No", No = "Control Group")
```

Relevel perspective taking and the emotional moderator so that spontaneous and no emotional cue are at level 1. 
```{r}
intense_dat$persp_mod <- relevel(intense_dat$persp_mod, "Spontaneous (naturalistic)")
intense_dat$emo_mod <- relevel(intense_dat$emo_mod, "No")
```

#### Retrospective t-value signs
Publication 50 and 379 need their signs altering
```{r}
# Show current string
intense_dat$Emotional.Intensity...Between_Test[3]
intense_dat$Emotional.Intensity...Between_Test[6]
# Replace string with correct negative values
intense_dat$Emotional.Intensity...Between_Test[3] <- "t(76.74) = -0.18, p = .859"
intense_dat$Emotional.Intensity...Between_Test[6] <- "t(72) = -0.62, p = .537"
```

### Postive Emotion Data

```{r positive_data}
posit_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Positive Emotion`, `Positive Emotion - First_Mean`:`Positive Emotion - Between_Test`, -c(`Positive Emotion - First_Corr`, `Positive Emotion - Third_Corr`, `Positive Emotion - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Positive Emotion`, first_mean = `Positive Emotion - First_Mean`, third_mean = `Positive Emotion - Third_Mean`, first_sd = `Positive Emotion - First_SD`, third_sd = `Positive Emotion - Third_SD`, first_n = `Positive Emotion - First_N`, third_n = `Positive Emotion - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves only 3 studies for postiive emotion, with only two independent samples. As such, this DV will not be analysed any further due to insufficient data.

### Negative Emotion Data

```{r negative_data}
neg_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Negative Emotion`, `Negative Emotion - First_Mean`:`Negative Emotion - Between_Test`, -c(`Negative Emotion - First_Corr`, `Negative Emotion - Third_Corr`, `Negative Emotion - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Negative Emotion`, first_mean = `Negative Emotion - First_Mean`, third_mean = `Negative Emotion - Third_Mean`, first_sd = `Negative Emotion - First_SD`, third_sd = `Negative Emotion - Third_SD`, first_n = `Negative Emotion - First_N`, third_n = `Negative Emotion - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 5 studies for Negative Emotion from 4 independent samples. I'm reluctant to combine so few studies together, especially given that 3 are clinical, and that there are 3 types of perspective taking used. 

The pattern of findings may be of interest, so further calculations will be done for now pending discussion. 

Calculate the effect sizes for the Negative Emotion data
```{r negative_effsiz}
neg_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = neg_dat)
```


# Univariate Analysis

Decided to break with my original multivariate analysis plan for the sake of the write up. Will come back to this afterwards and do a multivariate analysis and evaluate whether this effects the results. 

In line with part of the original plan, all models will be random effects.

### Vividness

#### Base Model

```{r vivid_model}
vivid_base <- rma(yi, vi, data = vivid_dat, test = "knha")
summary(vivid_base)
```

```{r vivid_for}
forest(vivid_base, addfit = T, slab = vivid_dat$Authors, cex = .8)
```

#### Perspective Type

Check the levels of perspective taking and assign the contrasts
```{r vivid_pcontrasts}
levels(vivid_dat$persp_mod)
contrasts(vivid_dat$persp_mod) <- cbind(spon_vs_force, deli_vs_shift)
```

```{r vivid_pmodsN}
table(vivid_dat$persp_mod)
```

Running the model
```{r vivid_pmodel}
vivid_pmod <- rma(yi = yi, vi = vi, mods = ~ persp_mod, data = vivid_dat, test = "knha")
summary(vivid_pmod)
```

```{r vivid_pfor}
# forest(vivid_pmod, addfit = T, slab = vivid_dat$Authors, cex = .7)
```

#### Emotional Cues

Relevels the emotional moderators so it'll match the contrast coding and counts the k per group
```{r vivid_emodsN}
vivid_dat$emo_mod <- relevel(vivid_dat$emo_mod, ref = "No")
table(vivid_dat$emo_mod)
```

Set up orthagonal contrasts
```{r vivid_econtrasts}
contrasts(vivid_dat$emo_mod) <- cbind(none_vs_emo, pos_vs_neg)
```

This analysis looks at all studies together, implicitly combining the two clinical and 10 non-clinical samples.
```{r vivid_emod}
vivid_emo <- rma(yi, vi, mods = ~ emo_mod, data = vivid_dat)
summary(vivid_emo)
```

```{r vivid_efor}
#forest(vivid_emo, addfit = T, cex = .7)
```

As a partial sensitivity analysis will exclude the two clinical studies and rerun the model. Although based on the forest plot they don't appear to be substantially different and I don't expect any differences.

```{r vivid_emod2}
vivid_emo2 <- 
  vivid_dat %>%
  filter(., clinical_mod == "No") %>%
  rma(yi, vi, mods = ~ persp_mod, data = .)
summary(vivid_emo2)
forest(vivid_emo2)
```
The AIC, and BIC indicate the model without these studies in is a slighter better fit. Notably, none of the conclusions that may be drawn from the model are changed.

### Emotional Intensity

#### Base Model

```{r intense_mod}
intense_base <- rma(yi, vi, data = intense_dat, method = "REML", test = "knha")
summary(intense_base)
```

```{r intense_for}

```


```{r}
rstudent.rma.uni()
```

```{r}
intense_noout <- 
  intense_dat[-c(1),] %>%
  rma(yi, vi, data = ., method = "REML", test = "knha")
summary(intense_noout)  
forest(intense_noout)
```

# Sensitivity Analyses

## Type of estimator

Because the number of studies (k) is relatively small, the convergence on the 'true' weights will be in some doubt, and the assumptions of typical esitmation are hard to defend (i.e. ML, REML etc).
Alternative approaches to variance estimation include: 
* quasi-F / Hartung and Knapp - also reliant on parametric assumptions
* Huber-White - not reliant on parametric assumptions, however, the theory behind it requires large k

The following chunks compare the estimates of these approaches

```{r}
# Conventional approach

res.std <- list()
 
res.std$FE   <- rma(yi, vi, data = intense_dat, digits = 3, method = "FE")
res.std$ML   <- rma(yi, vi, data = intense_dat, digits = 3, method = "ML")
res.std$REML <- rma(yi, vi, data = intense_dat, digits = 3, method = "REML")
res.std$DL   <- rma(yi, vi, data = intense_dat, digits = 3, method = "DL")
res.std$HE   <- rma(yi, vi, data = intense_dat, digits = 3, method = "HE")
 
round(t(sapply(res.std, function(x) c(tau2=x$tau2, mu=x$b, se=x$se, z=x$zval, ci.lb=x$ci.lb, ci.ub=x$ci.ub))), 3)
```

```{r}
# Hartung and Knapp's approach
intense.knha <- list()
 
intense.knha$FE   <- rma(yi, vi, data= intense_dat, digits=3, method="FE", test="knha")
intense.knha$ML   <- rma(yi, vi, data=intense_dat, digits=3, method="ML", test="knha")
intense.knha$REML <- rma(yi, vi, data=intense_dat, digits=3, method="REML", test="knha")
intense.knha$DL   <- rma(yi, vi, data=intense_dat, digits=3, method="DL", test="knha")
intense.knha$HE   <- rma(yi, vi, data=intense_dat, digits=3, method="HE", test="knha")
 
round(t(sapply(intense.knha, function(x) c(tau2=x$tau2, mu=x$b, se=x$se, z=x$zval, ci.lb=x$ci.lb, ci.ub=x$ci.ub))), 3)
```

```{r}
# Huber-White approach, with small sample adjustment

intense.hw <- list()

intense.hw$FE   <- robust(res.std$FE,   cluster=intense_dat$Pub_ID, adjust=TRUE)
intense.hw$ML   <- robust(res.std$ML,   cluster=intense_dat$Pub_ID, adjust=TRUE)
intense.hw$REML <- robust(res.std$REML, cluster=intense_dat$Pub_ID, adjust=TRUE)
intense.hw$DL   <- robust(res.std$DL,   cluster=intense_dat$Pub_ID, adjust=TRUE)
intense.hw$HE   <- robust(res.std$HE,   cluster=intense_dat$Pub_ID, adjust=TRUE)
 
intense_hw <- as_tibble(round(t(sapply(intense.hw, function(x) c(tau2=x$tau2, mu=x$b, se=x$se, t=x$tval, ci.lb=x$ci.lb, ci.ub=x$ci.ub))), 3))
intense_hw$est  <- c("FE", "ML", "REML", "DL", "HE")
intense_hw %>% select(., est, tau2, mu, se , ci.lb, ci.ub)
```

```{r}
intense_labs <- c("McIsaac & Eich, 2002", 
                  "Sutin & Robins, 2010", 
                  "Bernsten & Rubin, 2006", 
                  "Robinaugh & McNally, 2010", 
                  "Marcotti & St Jacques, 2017", 
                  "Vella & Moulds, 2014", 
                  "Sutin & Robins, 2010", 
                  "Wisco & Nolen-Hoeksema, 2011", 
                  "Wisco & Nolen-Hoeksema, 2011, clinical"
                  )
```

#### Perspective Type
```{r}
intense_pmod <- rma(yi, vi, mods = ~ persp_mod, data = intense_dat)
summary(intense_pmod)
forest(intense_pmod)
```

```{r}
intense_emo <- rma(yi, vi, mods = ~ emo_mod, data = intense_dat)
summary(intense_emo)
forest(intense_emo)
```

Given that there's only one study that's looked at positive emotion in terms of emotional intensity it may be worth restricting the moderator analysis to negative (3 studies) vs neutral (5 studies) to reduce the number of parameters being estimated. However, this is not expected to make a difference. 

There's only one clinical study in this dv and it appears to be very similar to the other studies (see prior forest plot)

```{r}
intense_emo2 <- 
  intense_dat %>% 
  filter(., emo_mod %in% c("Negative Cue", "No")) %>%
  rma(yi, vi, mods = ~emo_mod, data = .)
summary(intense_emo2)
forest(intense_emo2)
```

