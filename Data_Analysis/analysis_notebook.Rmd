---
title: "Visual Perspective - Meta-Analysis"
author: Liam Marley
output: html_notebook:
  theme: flatly
  toc: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff=60), tidy = TRUE)
```

# Packages Used
```{r packages}
library(tidyverse)
library(metafor)
```

# Data Import and Tidying

## Load in the data
```{r data_loading}
qual_export <- read_csv("qual_export_24-07-18.csv")
```

## Data Tidying

Following chunk drops: the unecessary qualtrics variables and rows, correlational studies, and any research conducted at the memory level.

Correlational studies are dropped to be analysed separately, and studies done at the memory level have nearly always used single level statistics treating memories as participants. Which ignores the clustering and dependency in the data leading to spurious results. As such, they've been excluded as a form of quality control.

```{r}
qual_tidy <- 
  qual_export %>%
  select(-c(`Start Date`:`User Language`)) %>%
  filter(Analysis_Level == "Participants") %>%
  filter(Design_1 == "Experimental")
```

### Vividness Data

Only selects the variables to calculate effect sizes from and those that are necessary to identify the research source and potential moderators (emotional cues, clinical samples, and perspective nature).

Then renames these to variables more suited for conducting the analysis

Finally, it drops studies with any na values within these variables. Note, this will only drop studies that have no vividness scores not those with missing data, because missing data has been coded as -99 within qualtrics. 

```{r vividness_data}
vivid_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Vividness`, `Vividness - First_Mean`:`Vividness - Between_Test`, -c(`Vividness - First_Corr`, `Vividness - Third_Corr`, `Vividness - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Vividness`, first_mean = `Vividness - First_Mean`, third_mean = `Vividness - Third_Mean`, first_sd = `Vividness - First_SD`, third_sd = `Vividness - Third_SD`, first_n = `Vividness - First_N`, third_n = `Vividness - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 11 studies for vividness.

Recodes any missing Ns or SDs as NA from the -99 now that the drop_na argument has been used. These are being preserved in the analysis purely to represent the study's existence. 
```{r vivid_nas}
# recode missing SDs as NAs
vivid_dat$first_sd <- na_if(vivid_dat$first_sd, -99.00)
vivid_dat$third_sd<- na_if(vivid_dat$third_sd, -99.00)

# recode missing Ns as NAs
vivid_dat$first_n <- na_if(vivid_dat$first_n, -99)
vivid_dat$third_n <- na_if(vivid_dat$third_n, -99)
```

Calculate the effect sizes for the vividness data
```{r vivid_effsiz}
vivid_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = vivid_dat)
```

### Emotional Intensity Data

Follows exactky the same pattern and reasoning as the vividness data 

```{r intense_data}
intense_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Emotional Intensity`, `Emotional Intensity - First_Mean`:`Emotional Intensity - Between_Test`, -c(`Emotional Intensity - First_Corr`, `Emotional Intensity - Third_Corr`, `Emotional Intensity - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Emotional Intensity`, first_mean = `Emotional Intensity - First_Mean`, third_mean = `Emotional Intensity - Third_Mean`, first_sd = `Emotional Intensity - First_SD`, third_sd = `Emotional Intensity - Third_SD`, first_n = `Emotional Intensity - First_N`, third_n = `Emotional Intensity - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 9 studies for Emotional Intensity.

```{r intense_nas}
# recode missing SDs as NAs
intense_dat$first_sd <- na_if(intense_dat$first_sd, -99.00)
intense_dat$third_sd<- na_if(intense_dat$third_sd, -99.00)

# recode missing Ns as NAs
intense_dat$first_n <- na_if(intense_dat$first_n, -99)
intense_dat$third_n <- na_if(intense_dat$third_n, -99)
```

Calculate the effect sizes for the Emotional Intensity data
```{r intense_effsiz}
intense_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = intense_dat)
```

### Postive Emotion Data

```{r positive_data}
posit_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Positive Emotion`, `Positive Emotion - First_Mean`:`Positive Emotion - Between_Test`, -c(`Positive Emotion - First_Corr`, `Positive Emotion - Third_Corr`, `Positive Emotion - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Positive Emotion`, first_mean = `Positive Emotion - First_Mean`, third_mean = `Positive Emotion - Third_Mean`, first_sd = `Positive Emotion - First_SD`, third_sd = `Positive Emotion - Third_SD`, first_n = `Positive Emotion - First_N`, third_n = `Positive Emotion - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves only 2 studies for postiive emotion, both of which are from the same publication and sample (but different methods of cueing). As such, this DV will not be analysed any further due to insufficient data.

### Negative Emotion Data

```{r negative_data}
neg_dat <- 
  qual_tidy %>%
  select(Pub_ID:Study_ID, `Clinical_Mod - Selected Choice`, Emo_Mod, Perspective_Nature, `Outcome - Negative Emotion`, `Negative Emotion - First_Mean`:`Negative Emotion - Between_Test`, -c(`Negative Emotion - First_Corr`, `Negative Emotion - Third_Corr`, `Negative Emotion - What was the correlation with [Field-1] perspective?`)) %>%
  rename(outcome = `Outcome - Negative Emotion`, first_mean = `Negative Emotion - First_Mean`, third_mean = `Negative Emotion - Third_Mean`, first_sd = `Negative Emotion - First_SD`, third_sd = `Negative Emotion - Third_SD`, first_n = `Negative Emotion - First_N`, third_n = `Negative Emotion - Third_N`, clinical_mod = `Clinical_Mod - Selected Choice`, emo_mod = Emo_Mod, persp_mod = Perspective_Nature) %>%
  drop_na()
```

This leaves 4 studies for Negative Emotion from 3 independent samples. I'm reluctant to combine so few studies together, especially given that 3 are clinical, and that there are 3 types of perspective taking used. 

The pattern of findings may be of interest, so further calculations will be done for now pending discussion. 

Calculate the effect sizes for the Negative Emotion data
```{r negative_effsiz}
neg_dat <- escalc("SMD", m1i = first_mean, m2i = third_mean, sd1i = first_sd, sd2i = third_sd, n1i = first_n, n2i = third_n, data = neg_dat)
```

### Univariate vs Multivariate Analysis

Following from Gleser and Olkin's (2009) discussion of when univariate analysis can be appropriate I'm considering breaking with my original plan and conducting a univariate analysis for each dv. 

That said, it will be "less efficient statistically" and I'd rather not ignore the covariance between the dvs. However, the best method available to me, that I'm aware of, is to impute these based upon the psychometric properties of the tools used. But ensure that I use a range of plausible values to check whether the imputed values will affect the results. One downside here is I know from the coding process not all studies have used established measures. 